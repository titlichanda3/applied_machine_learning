{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b34ca06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\titli\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n",
      "2026/02/12 00:33:05 INFO mlflow.tracking.fluent: Experiment with name 'sms_spam_benchmarks' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/titli/Documents/sms-spam-dvc/mlruns/368038252911427570', creation_time=1770836585445, experiment_id='368038252911427570', last_update_time=1770836585445, lifecycle_stage='active', name='sms_spam_benchmarks', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"file:///C:/Users/titli/Documents/sms-spam-dvc/mlruns\")\n",
    "mlflow.set_experiment(\"sms_spam_benchmarks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a412960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df  = pd.read_csv(\"data/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34717a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_df[\"text\"])\n",
    "y_train = train_df[\"label\"]\n",
    "\n",
    "X_test = vectorizer.transform(test_df[\"text\"])\n",
    "y_test = test_df[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a57619dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def compute_aucpr(model, X, y):\n",
    "    \"\"\"\n",
    "    Compute AUCPR (Average Precision Score)\n",
    "\n",
    "    Works for:\n",
    "    - Logistic Regression (decision_function)\n",
    "    - Linear SVM (decision_function)\n",
    "    - Naive Bayes (predict_proba)\n",
    "    \"\"\"\n",
    "\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        scores = model.decision_function(X)\n",
    "\n",
    "    elif hasattr(model, \"predict_proba\"):\n",
    "        scores = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Model does not support scoring for AUCPR\")\n",
    "\n",
    "    return average_precision_score(y, scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cdc7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "def run_experiment(model, name):\n",
    "\n",
    "    with mlflow.start_run(run_name=name):\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        aucpr = compute_aucpr(model, X_test, y_test)\n",
    "\n",
    "        mlflow.log_metric(\"AUCPR\", aucpr)\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        print(name, \"AUCPR =\", aucpr)\n",
    "\n",
    "        return aucpr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "769f60b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/12 00:50:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\titli\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\models\\model.py:1209: FutureWarning: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization.The recommended safe alternative is the 'skops' format.\n",
      "  flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n",
      "2026/02/12 00:50:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression AUCPR = 0.9638042020737022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\titli\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\models\\model.py:1209: FutureWarning: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization.The recommended safe alternative is the 'skops' format.\n",
      "  flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n",
      "2026/02/12 00:50:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes AUCPR = 0.9679638068159969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\titli\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\models\\model.py:1209: FutureWarning: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization.The recommended safe alternative is the 'skops' format.\n",
      "  flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVM AUCPR = 0.967608503553906\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "    \"NaiveBayes\": MultinomialNB(),\n",
    "    \"LinearSVM\": LinearSVC(dual=\"auto\")\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    results[name] = run_experiment(model, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42ec4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, name):\n",
    "\n",
    "    with mlflow.start_run(run_name=name):\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        aucpr = compute_aucpr(model, X_test, y_test)\n",
    "\n",
    "        mlflow.log_metric(\"AUCPR\", aucpr)\n",
    "\n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(model, name=\"model\")\n",
    "\n",
    "        # Register model in MLflow Model Registry\n",
    "        mlflow.register_model(\n",
    "            model_uri=f\"runs:/{mlflow.active_run().info.run_id}/model\",\n",
    "            name=name\n",
    "        )\n",
    "\n",
    "        print(name, \"AUCPR =\", aucpr)\n",
    "\n",
    "        return aucpr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5565487a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Comparison (AUCPR):\n",
      "\n",
      "LogisticRegression: AUCPR = 0.9638\n",
      "NaiveBayes: AUCPR = 0.9680\n",
      "LinearSVM: AUCPR = 0.9676\n",
      "\n",
      "Best model selected: NaiveBayes\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal Model Comparison (AUCPR):\\n\")\n",
    "\n",
    "for model, score in results.items():\n",
    "    print(f\"{model}: AUCPR = {score:.4f}\")\n",
    "\n",
    "best_model = max(results, key=results.get)\n",
    "print(\"\\nBest model selected:\", best_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
